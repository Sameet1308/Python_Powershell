import json
import boto3
import csv
import io

s3 = boto3.client('s3')
glue = boto3.client('glue')

def lambda_handler(event, context):
    # Extract bucket name and file key from the event
    bucket = event['Records'][0]['s3']['bucket']['name']
    key = event['Records'][0]['s3']['object']['key']
    
    # Get the CSV file from S3
    response = s3.get_object(Bucket=bucket, Key=key)
    content = response['Body'].read().decode('utf-8')
    
    # Infer schema from the CSV file
    csv_reader = csv.DictReader(io.StringIO(content))
    columns = csv_reader.fieldnames
    
    # Define Glue table columns based on CSV headers
    glue_columns = []
    for col in columns:
        glue_columns.append({'Name': col, 'Type': 'string'})
    
    # Create Glue table
    table_name = key.split('/')[-1].replace('.csv', '')  # Use the file name as table name
    database_name = 'your_glue_database'  # Replace with your Glue database name
    
    glue.create_table(
        DatabaseName=database_name,
        TableInput={
            'Name': table_name,
            'StorageDescriptor': {
                'Columns': glue_columns,
                'Location': f's3://{bucket}/{key}',
                'InputFormat': 'org.apache.hadoop.mapred.TextInputFormat',
                'OutputFormat': 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',
                'Compressed': False,
                'SerdeInfo': {
                    'SerializationLibrary': 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',
                    'Parameters': {
                        'field.delim': ','
                    }
                }
            },
            'TableType': 'EXTERNAL_TABLE'
        }
    )
    
    return {
        'statusCode': 200,
        'body': json.dumps('Glue table created successfully!')
    }
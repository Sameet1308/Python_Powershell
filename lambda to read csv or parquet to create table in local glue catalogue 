import boto3
import pandas as pd
import pyarrow.parquet as pq
from io import StringIO, BytesIO
import logging

# Initialize clients and logger
s3_client = boto3.client('s3')
glue_client = boto3.client('glue')
logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event, context):
    try:
        # Define bucket name and prefix
        bucket_name = 'your_bucket_name'
        prefix = 'your/prefix/path/'
        
        # List all objects in the prefix
        response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
        objects = response.get('Contents', [])
        
        for obj in objects:
            object_key = obj['Key']
            try:
                if object_key.endswith('.csv'):
                    create_or_update_glue_table_from_csv(bucket_name, object_key)
                elif object_key.endswith('.parquet'):
                    create_or_update_glue_table_from_parquet(bucket_name, object_key)
            except Exception as e:
                logger.error(f"Failed to process file {object_key}: {e}")
        
        return {
            'statusCode': 200,
            'body': 'Successfully processed all files in the prefix'
        }
    except Exception as e:
        logger.error(f"Failed to process S3 event: {e}")
        return {
            'statusCode': 500,
            'body': 'Error processing files'
        }

def create_or_update_glue_table_from_csv(bucket, key):
    try:
        # Read the CSV file from S3
        response = s3_client.get_object(Bucket=bucket, Key=key)
        csv_content = response['Body'].read().decode('utf-8')
        df = pd.read_csv(StringIO(csv_content))
        
        # Infer the schema from the DataFrame
        columns = df.columns
        new_schema = infer_schema(df, columns)
        
        # Check if table exists
        table_name = key.split('/')[-1].split('.')[0]
        database_name = 'your_glue_database'
        
        if check_if_table_exists(database_name, table_name):
            # Compare schemas
            existing_schema = get_existing_schema(database_name, table_name)
            if schemas_are_equal(existing_schema, new_schema):
                logger.info(f"No schema change detected for table {table_name}. Skipping update.")
                return
        
        # Define Glue table properties
        create_or_update_glue_table(database_name, table_name, bucket, key, new_schema, 'csv')
    except Exception as e:
        logger.error(f"Failed to create or update table from CSV {key}: {e}")
        raise

def create_or_update_glue_table_from_parquet(bucket, key):
    try:
        # Read the Parquet file from S3
        response = s3_client.get_object(Bucket=bucket, Key=key)
        parquet_content = response['Body'].read()
        table = pq.read_table(BytesIO(parquet_content))
        df = table.to_pandas()
        
        # Infer the schema from the DataFrame
        columns = df.columns
        new_schema = infer_schema(df, columns)
        
        # Check if table exists
        table_name = key.split('/')[-1].split('.')[0]
        database_name = 'your_glue_database'
        
        if check_if_table_exists(database_name, table_name):
            # Compare schemas
            existing_schema = get_existing_schema(database_name, table_name)
            if schemas_are_equal(existing_schema, new_schema):
                logger.info(f"No schema change detected for table {table_name}. Skipping update.")
                return
        
        # Define Glue table properties
        create_or_update_glue_table(database_name, table_name, bucket, key, new_schema, 'parquet')
    except Exception as e:
        logger.error(f"Failed to create or update table from Parquet {key}: {e}")
        raise

def check_if_table_exists(database_name, table_name):
    try:
        glue_client.get_table(DatabaseName=database_name, Name=table_name)
        return True
    except glue_client.exceptions.EntityNotFoundException:
        return False
    except Exception as e:
        logger.error(f"Error checking if table {table_name} exists: {e}")
        raise

def get_existing_schema(database_name, table_name):
    try:
        response = glue_client.get_table(DatabaseName=database_name, Name=table_name)
        columns = response['Table']['StorageDescriptor']['Columns']
        return columns
    except Exception as e:
        logger.error(f"Error retrieving schema for table {table_name}: {e}")
        raise

def schemas_are_equal(schema1, schema2):
    return schema1 == schema2

def infer_schema(df, columns):
    schema = []
    try:
        for col in columns:
            dtype = df[col].dtype
            if pd.api.types.is_integer_dtype(dtype):
                glue_type = 'int'
            elif pd.api.types.is_float_dtype(dtype):
                glue_type = 'float'
            elif pd.api.types.is_bool_dtype(dtype):
                glue_type = 'boolean'
            elif pd.api.types.is_datetime64_any_dtype(dtype):
                glue_type = 'timestamp'
            else:
                glue_type = 'string'
            
            schema.append({'Name': col, 'Type': glue_type})
        return schema
    except Exception as e:
        logger.error(f"Failed to infer schema: {e}")
        raise

def create_or_update_glue_table(database_name, table_name, bucket, key, schema, file_format):
    try:
        input_format = 'org.apache.hadoop.mapred.TextInputFormat' if file_format == 'csv' else 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'
        output_format = 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
        serde_library = 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe' if file_format == 'csv' else 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
        
        table_input = {
            'Name': table_name,
            'StorageDescriptor': {
                'Columns': schema,
                'Location': f's3://{bucket}/{key}',
                'InputFormat': input_format,
                'OutputFormat': output_format,
                'SerdeInfo': {
                    'SerializationLibrary': serde_library
                }
            },
            'TableType': 'EXTERNAL_TABLE',
        }
        
        if check_if_table_exists(database_name, table_name):
            glue_client.update_table(DatabaseName=database_name, TableInput=table_input)
            logger.info(f"Successfully updated table {table_name} in Glue database {database_name}")
        else:
            glue_client.create_table(DatabaseName=database_name, TableInput=table_input)
            logger.info(f"Successfully created table {table_name} in Glue database {database_name}")
    except Exception as e:
        logger.error(f"Failed to create or update Glue table for {key}: {e}")
        raise
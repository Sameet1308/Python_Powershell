import re
import pandas as pd

# Read log file lines
def read_log_file(file_path):
    try:
        with open(file_path, 'r') as file:
            return file.readlines()
    except Exception as e:
        print(f"Error reading file: {e}")
        return []

# Clean log lines from unwanted characters like timestamps and line numbers
def clean_log_lines(lines):
    cleaned_lines = []
    for line in lines:
        # Example of cleaning a complex line with multiple possible prefixes:
        # '2023-04-04 12:34:56 00123 Some identifier SQL Select...'
        # This regex will remove any leading date/time and digits or identifiers up to the SQL keyword.
        cleaned_line = re.sub(r'^\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\s+\d+\s+[^\s]+\s+(?=(SELECT|INSERT|UPDATE|DELETE|WITH))', '', line, flags=re.IGNORECASE)
        cleaned_lines.append(cleaned_line)
    return cleaned_lines

# Concatenate SQL statements
def concatenate_sql_lines(lines):
    sql_statements = []
    current_statement = []
    capturing = False
    
    for line in lines:
        if 'SELECT' in line and not capturing:
            capturing = True
            current_statement = [line]
        elif capturing:
            current_statement.append(line)
            if 'FROM' in line:
                next_word_match = re.search(r'FROM\s+(\w+)', line)
                if next_word_match:
                    next_word = next_word_match.group(1)
                    current_statement.append(next_word)
                    sql_statements.append(' '.join(current_statement).strip())
                    capturing = False
                    current_statement = []

    if capturing and current_statement:
        sql_statements.append(' '.join(current_statement).strip())

    return sql_statements

# Extract table names and columns from SQL statements
def extract_tables_and_columns(sql_statements):
    table_columns = []
    
    for sql in sql_statements:
        column_match = re.findall(r'SELECT (.*?) FROM', sql, re.IGNORECASE)
        table_match = re.search(r'FROM\s+(\w+)', sql, re.IGNORECASE)
        
        if column_match and table_match:
            columns = column_match[0].split(',')
            columns = [col.strip() for col in columns]
            table = table_match.group(1)
            table_columns.append({'table': table, 'columns': columns})

    return table_columns

# Convert to DataFrame
def to_dataframe(table_columns):
    return pd.DataFrame(table_columns)

# Main function
def main():
    log_file_path = 'path/to/your/log_file.log'  # Update the path to your log file
    lines = read_log_file(log_file_path)
    cleaned_lines = clean_log_lines(lines)
    sql_statements = concatenate_sql_lines(cleaned_lines)
    table_columns = extract_tables_and_columns(sql_statements)
    df = to_dataframe(table_columns)
    print(df)

if __name__ == "__main__":
    main()
